# ğŸ¤– Guide d'intÃ©gration Groq AI

## Configuration de l'Assistant IA

L'application utilise **Groq** pour l'assistant IA conversationnel.

### ğŸ“ Ã‰tapes de configuration

#### 1. Obtenir une clÃ© API Groq (Gratuit)

1. Allez sur https://console.groq.com
2. CrÃ©ez un compte (gratuit)
3. Allez dans "API Keys"
4. Cliquez sur "Create API Key"
5. Copiez votre clÃ© (commence par `gsk_...`)

#### 2. Configurer la clÃ© API

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```bash
# Copier le fichier exemple
cp .env.example .env
```

Puis Ã©ditez `.env` et ajoutez votre clÃ© :

```env
VITE_GROQ_API_KEY=gsk_votre_cle_api_ici
```

âš ï¸ **Important** : Le fichier `.env` est dans `.gitignore` et ne sera jamais commitÃ©.

#### 3. RedÃ©marrer le serveur de dÃ©veloppement

```bash
npm run dev
```

### âœ¨ FonctionnalitÃ©s de l'Assistant IA

L'assistant IA peut :

- âœ… RÃ©pondre aux questions sur les Å“uvres du musÃ©e
- âœ… Fournir des informations culturelles et historiques
- âœ… Recommander des Å“uvres similaires
- âœ… Expliquer le contexte des civilisations africaines
- âœ… Communiquer en **3 langues** (FranÃ§ais, Anglais, Wolof)

### ğŸ¯ Contexte fourni Ã  l'IA

L'assistant a accÃ¨s Ã  :

- Toutes les Å“uvres de la collection avec descriptions complÃ¨tes
- Informations sur les origines gÃ©ographiques
- PÃ©riodes historiques
- Contextes culturels
- CatÃ©gories (Sculpture, Textile, CÃ©ramique, etc.)

### ğŸš€ ModÃ¨le utilisÃ©

**Llama 3.3 70B Versatile** (via Groq)
- Ultra-rapide (~500 tokens/seconde)
- TrÃ¨s performant en multilingue
- Contexte jusqu'Ã  32K tokens
- Gratuit avec limites gÃ©nÃ©reuses

### ğŸ“Š Limites gratuites Groq

- **30 requÃªtes/minute**
- **14,400 requÃªtes/jour**
- Largement suffisant pour un prototype/hackathon

### ğŸ”§ Configuration avancÃ©e

Modifier le modÃ¨le ou les paramÃ¨tres dans `src/services/groqService.ts` :

```typescript
const chatCompletion = await groq.chat.completions.create({
  messages: [systemMessage, ...messages],
  model: "llama-3.3-70b-versatile", // Changer le modÃ¨le
  temperature: 0.7, // CrÃ©ativitÃ© (0-1)
  max_tokens: 500, // Longueur max de rÃ©ponse
  top_p: 1,
  stream: false,
});
```

### ğŸ¨ Personnalisation de l'interface

Le composant `AIAssistant.tsx` est entiÃ¨rement personnalisable :

- Couleurs terracotta (#D17842)
- Dark mode supportÃ©
- Responsive design
- Animations fluides

### ğŸ› RÃ©solution de problÃ¨mes

#### L'assistant ne rÃ©pond pas

1. VÃ©rifiez que la clÃ© API est correcte dans `.env`
2. VÃ©rifiez la console du navigateur pour les erreurs
3. Assurez-vous d'avoir redÃ©marrÃ© le serveur aprÃ¨s modification de `.env`

#### Erreur "rate limit"

Vous avez dÃ©passÃ© les limites gratuites. Attendez quelques minutes.

#### Erreur "401 Unauthorized"

Votre clÃ© API est incorrecte ou expirÃ©e. GÃ©nÃ©rez-en une nouvelle sur console.groq.com

### ğŸŒ DÃ©ploiement

Pour le dÃ©ploiement en production :

1. **Vercel/Netlify** : Ajoutez `VITE_GROQ_API_KEY` dans les variables d'environnement
2. **Important** : Ne committez JAMAIS votre clÃ© API

### ğŸ“š Documentation

- [Documentation Groq](https://console.groq.com/docs)
- [Groq SDK GitHub](https://github.com/groq/groq-typescript)
- [ModÃ¨les disponibles](https://console.groq.com/docs/models)

### ğŸ’¡ Exemples de questions

Testez l'assistant avec :

- "Parle-moi du Masque Gelede"
- "Quelle est l'origine du Tissu Kente ?"
- "Quelles Å“uvres viennent du NigÃ©ria ?"
- "Explique-moi le contexte culturel des sculptures"
- "Recommande-moi une Å“uvre textile"

---

**CrÃ©Ã© pour le Hackathon Dakar Slush'D 2025** ğŸ‡¸ğŸ‡³
